{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import json\n",
    "import os\n",
    "import music21 as m21\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileHelper:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def load_file_as_str(self, file_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Loads the file at a specificed path, returns an error otherwise\n",
    "        \n",
    "        :param file_path (str): The path to the file you want to load\n",
    "        :return _file a str of the contents of the file\n",
    "        \"\"\"\n",
    "        _file = \"\"\n",
    "        try:\n",
    "            with open(file_path, \"r\") as fp:\n",
    "                _file = fp.read()\n",
    "            return _file\n",
    "        except Exception:\n",
    "            raise Exception(f\"Error reading file at: {file_path}\")\n",
    "\n",
    "    # TODO: Might not need this\n",
    "    def readBytes(self, file_path) -> bytes:\n",
    "        try:\n",
    "            with open(file_path, \"rb\") as fb:\n",
    "                file_bytes = fb.read()\n",
    "                return file_bytes\n",
    "        except Exception:\n",
    "            raise Exception(f\"Error trying to read bytes at: {file_path}\")\n",
    "            \n",
    "    def loadJSON(self, file_path) -> dict:\n",
    "        try:\n",
    "            with open(file_path) as json_data:\n",
    "                data = json.load(json_data)\n",
    "            return data\n",
    "        except Exception:\n",
    "            raise Exception(f\"Could not open file located at: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# durations are expressed in quarter length\n",
    "ACCEPTABLE_DURATIONS = [\n",
    "    0.25, # 16th note\n",
    "    0.5, # 8th note\n",
    "    0.75,\n",
    "    1.0, # quarter note\n",
    "    1.5,\n",
    "    2, # half note\n",
    "    3,\n",
    "    4 # whole note\n",
    "]\n",
    "\n",
    "class MusicHelper:\n",
    "    def __init__(self, file_helper: FileHelper, acceptable_durations=ACCEPTABLE_DURATIONS):\n",
    "        \"\"\"\n",
    "        :param file_helper (FileHelper): This is a file_helper object to help with writing/reading files\n",
    "        :param acceptable_durations (List[float]): This is the range of notes that are ok to add for the model\n",
    "        :return MusicHelper: This is the constructor for the class\n",
    "        \"\"\"\n",
    "        print(\"MusicHelper has been created...\")\n",
    "        self.acceptable_durations = acceptable_durations\n",
    "        self._file_helper = file_helper\n",
    "\n",
    "    def load_songs(self, dataset_path: str, file_type: str):\n",
    "        \"\"\"\n",
    "        Loads all pieces of a specific file type\n",
    "\n",
    "        :param dataset_path (str): Path to dataset\n",
    "        :param file_stype (str): The file type you want to load\n",
    "        :return songs (list of m21 streams): List containing all pieces\n",
    "        \"\"\"\n",
    "        print(\"Loading songs....\")\n",
    "        songs = []\n",
    "        len_file_ext = len(file_type)\n",
    "\n",
    "        # go through all the files in dataset and load them with music21\n",
    "        for path, _, files in os.walk(dataset_path):\n",
    "            for file in files:\n",
    "\n",
    "                # consider only files of the target type\n",
    "                if file[-len_file_ext:] == file_type:\n",
    "                    try:\n",
    "                        song = m21.converter.parse(os.path.join(path, file))\n",
    "                        if self.monophonic(song):\n",
    "                            songs.append(song)\n",
    "                    except Exception:\n",
    "                        print(f\"Error processing file located at: {os.path.join(path, file)}\")\n",
    "        return songs\n",
    "    \n",
    "    def monophonic(self, stream) -> bool:\n",
    "        try:\n",
    "            length = len(m21.instrument.partitionByInstrument(stream).parts)\n",
    "        except:\n",
    "            length = 0\n",
    "        return length == 1\n",
    "\n",
    "    def transpose_song(self, song, major_key: str, minor_key: str):\n",
    "        \"\"\"\n",
    "        Transposes song to a specified major/minor key.\n",
    "        If the song is in a major scale it is transposed to the specified key, vice versa\n",
    "\n",
    "        Defaults are in place in case the programmer forgets them\n",
    "\n",
    "        :param song (m21 stream): The song to transpose\n",
    "        :param major_key (str): The musical major key you want to transpose to\n",
    "        :param minor_key (str): The musical minor key you want to transpose to\n",
    "        :return transposed_song (m21 stream):\n",
    "        \"\"\"\n",
    "        #print(\"Transposing song....\")\n",
    "        # get key from the song\n",
    "        parts = song.getElementsByClass(m21.stream.Part)\n",
    "        measures_part0 = parts[0].getElementsByClass(m21.stream.Measure)\n",
    "        key = song.analyze(\"key\")\n",
    "\n",
    "        # get interval for transposition. E.g., Bmaj -> Cmaj\n",
    "        if key.mode == \"major\":\n",
    "            interval = m21.interval.Interval(key.tonic, m21.pitch.Pitch(\"C\"))\n",
    "        elif key.mode == \"minor\":\n",
    "            interval = m21.interval.Interval(key.tonic, m21.pitch.Pitch(\"A\"))\n",
    "\n",
    "        # transpose song by calculated interval\n",
    "        tranposed_song = song.transpose(interval)\n",
    "        return tranposed_song.chordify()\n",
    "\n",
    "    def encode_song(self, song, time_step=0.25):\n",
    "        \"\"\"\n",
    "        Converts a score into a time-series-like music representation. Each item in the encoded list represents 'min_duration'\n",
    "        quarter lengths. The symbols used at each step are: integers for MIDI notes, 'r' for representing a rest, and '_'\n",
    "        for representing notes/rests that are carried over into a new time step. Here's a sample encoding:\n",
    "\n",
    "            [\"r\", \"_\", \"60\", \"_\", \"_\", \"_\", \"72\" \"_\"]\n",
    "\n",
    "        :param song (m21 stream): Piece to encode\n",
    "        :param time_step (float): Duration of each time step in quarter length\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        #print(\"Encoding Song...\")\n",
    "        encoded_song = []\n",
    "\n",
    "        for event in song.flat.notesAndRests:\n",
    "\n",
    "            # handle notes\n",
    "            if isinstance(event, m21.note.Note):\n",
    "                symbol = event.pitch.midi # 60\n",
    "            # handle rests\n",
    "            elif isinstance(event, m21.note.Rest):\n",
    "                symbol = \"r\"\n",
    "            elif isinstance(event, m21.chord.Chord):\n",
    "                symbol = '.'.join(str(n) for n in event.normalOrder)\n",
    "\n",
    "            # convert the note/rest into time series notation\n",
    "            steps = int(event.duration.quarterLength / time_step)\n",
    "            for step in range(steps):\n",
    "\n",
    "                # if it's the first time we see a note/rest, let's encode it. Otherwise, it means we're carrying the same\n",
    "                # symbol in a new time step\n",
    "                if step == 0:\n",
    "                    encoded_song.append(symbol)\n",
    "                else:\n",
    "                    encoded_song.append(\"_\")\n",
    "\n",
    "        # cast encoded song to str\n",
    "        encoded_song = \" \".join(map(str, encoded_song))\n",
    "\n",
    "        return encoded_song\n",
    "\n",
    "    def convert_songs_to_int(self, songs: str, mapping_path:str):\n",
    "        \"\"\" \n",
    "        Maps the symbol in the song to an integer as dictated by the mappings.json file you create\n",
    "        earlier in training\n",
    "\n",
    "        :param songs (str): The giant song string you are currently using\n",
    "        :mapping_path (str): Path to your mappins.json file\n",
    "        :return int_songs\n",
    "        \"\"\"\n",
    "        int_songs = []\n",
    "        \n",
    "        # load mappings\n",
    "        # TODO: Make the file_helper do this\n",
    "        with open(mapping_path, \"r\") as fp:\n",
    "            mappings = json.load(fp)\n",
    "\n",
    "        # cast songs string to a list\n",
    "        songs = songs.split()\n",
    "\n",
    "        # map sings to int\n",
    "        for symbol in songs:\n",
    "            # TODO: Add some defensive coding strats here if key !exists \n",
    "            int_songs.append(mappings[symbol])\n",
    "\n",
    "        return int_songs\n",
    "\n",
    "    def create_mapping(self, songs: str, mapping_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Creates a json file that maps the symbols in the song dataset onto integers\n",
    "        This mappins file is EXTREMELY important for further training, dont lose it!\n",
    "\n",
    "        :param songs (str): String with all songs\n",
    "        :param mapping_path (str): Path where to save mapping\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        mappings = {}\n",
    "\n",
    "        # identify the vocabulary\n",
    "        songs = songs.split()\n",
    "        vocabulary = list(set(songs))\n",
    "\n",
    "        # create mappings\n",
    "        for i, symbol in enumerate(vocabulary):\n",
    "            mappings[symbol] = i\n",
    "\n",
    "        # save voabulary to a json file\n",
    "        # TODO: Have the file_helper do this\n",
    "        with open(mapping_path, \"w+\") as fp:\n",
    "            json.dump(mappings, fp, indent=4)\n",
    "\n",
    "    def generate_training_sequences(self, sequence_length: int, single_file_dataset_path: str, mapping_path: str):\n",
    "        \"\"\" \n",
    "        This creates representations of our data that can now be fed to an LSTM model\n",
    "\n",
    "        :param sequence_length (int): The length of the \"sliding window\" we're using to refeed samples\n",
    "        :param single_file_dataset_path (str): The file generated by create_single_file_dataset\n",
    "        :param mapping_path (str): The mapping file that maps symbols to ints\n",
    "        :return inputs, targets (3D Numpy Array): This is a 3d Numpy array/tensor for the model\n",
    "        \"\"\"\n",
    "        # What this is trying to create in the model:\n",
    "        # [11, 12, 13, 14, ...] -> inputs:[11, 12],  target:[13]\n",
    "\n",
    "        # load songs and map them to int\n",
    "        songs = self._file_helper.load_file_as_str(single_file_dataset_path)\n",
    "        int_songs = self.convert_songs_to_int(songs, mapping_path)\n",
    "\n",
    "        # generate the training sequences\n",
    "        # 100 symbols, seq_len = 64, 100 - 64 = 36 sequences we can generate\n",
    "        inputs = []\n",
    "        targets = []\n",
    "        num_sequences = len(int_songs) - sequence_length\n",
    "\n",
    "        # This loops generates the training slices plus the target to predict\n",
    "        for i in range(num_sequences):\n",
    "            inputs.append(int_songs[i:i+sequence_length])\n",
    "            targets.append(int_songs[i+sequence_length])\n",
    "\n",
    "        # one-hot encode the sequences\n",
    "        # inputs: (# of sequences, sequence length, vocabulary size)\n",
    "        vocabulary_size = len(set(int_songs))\n",
    "        inputs = keras.utils.to_categorical(inputs, num_classes=vocabulary_size, dtype=np.uint8)\n",
    "        targets = np.array(targets)\n",
    "\n",
    "        # Inputs will be a 3D Numpy array as demonstrated above\n",
    "        return inputs, targets\n",
    "\n",
    "\n",
    "    def create_single_file_dataset(self, encoded_song_path: str, file_dataset_path: str, sequence_length: int) -> str:\n",
    "        \"\"\"\n",
    "        Generates a file collating all the encoded songs and adding new piece delimiters. It then saves that to disc and returns the song\n",
    "\n",
    "        :param dataset_path (str): Path to folder containing the encoded songs\n",
    "        :param file_dataset_path (str): Path to file for saving songs in single txt file\n",
    "        :param sequence_length (int): # of time steps to be considered for training\n",
    "        :return songs (str): String containing all songs in dataset + delimiters\n",
    "        \"\"\"\n",
    "\n",
    "        new_song_delimiter = \"/ \" * sequence_length\n",
    "        songs = \"\"\n",
    "\n",
    "        # load encoded songs and add delimiters\n",
    "        for path, _, files in os.walk(encoded_song_path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(path, file)\n",
    "                song = self._file_helper.load_file_as_str(file_path)\n",
    "                songs = songs + song + \" \" + new_song_delimiter\n",
    "\n",
    "        # remove empty space from last character of string\n",
    "        songs = songs[:-1]\n",
    "\n",
    "        # save string that contains all the dataset\n",
    "        # TODO: Move to file helper + add defensive checks\n",
    "        with open(file_dataset_path, \"w+\") as fp:\n",
    "            fp.write(songs)\n",
    "\n",
    "        return songs\n",
    "\n",
    "    def preprocess_songs(self, dataset_path: str, song_txt_path: str, major_key: str, minor_key: str, file_type: str) -> None:\n",
    "        \"\"\"\n",
    "        A method that encompasses many of the preprocessing operations needed for converting\n",
    "        the songs to a helpful representation for our RNN/LSTM/Time Series centric models\n",
    "\n",
    "        :param dataset_path (str): The complete path to the dataset you want to load\n",
    "        :param song_text_path (str): The complete path where the song_txt file will be saved\n",
    "        :param major_key (str): What major key we transpose songs to\n",
    "        :param minor_key (str): What minor key we transpose songs to\n",
    "        :return None: This method returns nothing\n",
    "        \"\"\"\n",
    "\n",
    "        # load folk songs\n",
    "        #print(\"Loading songs...\")\n",
    "        songs = self.load_songs(dataset_path, file_type)\n",
    "        print(f\"Loaded {len(songs)} songs.\")\n",
    "\n",
    "        for i, song in enumerate(songs):\n",
    "            # transpose songs to the major/minor key we want\n",
    "            song = self.transpose_song(song, major_key, minor_key)\n",
    "\n",
    "            # encode songs with music time series representation\n",
    "            encoded_song = self.encode_song(song)\n",
    "\n",
    "            # save songs to text file\n",
    "            save_path = os.path.join(song_txt_path, str(i))\n",
    "            # TODO: Have file helper do this + defensive checks\n",
    "            with open(save_path, \"w+\") as fp:\n",
    "                fp.write(encoded_song)\n",
    "\n",
    "    # TODO: Ensure this is as genric as possible and applicate \n",
    "    def song_data_pipeline(self, pipeline_config: dict) -> None:\n",
    "        \"\"\" \n",
    "        A single method that encapsulates the entire preprocessing pipeline for files. \n",
    "\n",
    "        :param pipeline_config (dict): A dict containing all the parameters and arguments for the methods being called.\n",
    "        :return None: This method returns nothing\n",
    "        \"\"\"\n",
    "\n",
    "        # TODO: Add better defensive coding, throughout the entire method really\n",
    "        if (len(pipeline_config.keys()) < 6):\n",
    "             raise Exception(\"Not enough keys, returning...\")\n",
    "        \n",
    "        print(\"Entering song preprocessing...\")\n",
    "        self.preprocess_songs(\n",
    "           pipeline_config['DATASET_PATH'], \n",
    "           pipeline_config['ENCODED_SONG_PATH'],\n",
    "           pipeline_config['MAJOR_KEY'],\n",
    "           pipeline_config['MINOR_KEY'],\n",
    "           pipeline_config['FILE_TYPE']\n",
    "        )\n",
    "        \n",
    "        songs = self.create_single_file_dataset(\n",
    "            pipeline_config['ENCODED_SONG_PATH'],\n",
    "           pipeline_config['SINGLE_FILE_DATASET_PATH'],\n",
    "           pipeline_config['SEQUENCE_LENGTH']\n",
    "        )\n",
    "\n",
    "        self.create_mapping(songs, pipeline_config['MAPPING_PATH'])\n",
    "        print(\"Finished preprocessing songs!\")\n",
    "\n",
    "        print(\"Generating training data...\")\n",
    "        inputs, targets = self.generate_training_sequences(\n",
    "            pipeline_config['SEQUENCE_LENGTH'],\n",
    "            pipeline_config['SINGLE_FILE_DATASET_PATH'],\n",
    "            pipeline_config['MAPPING_PATH']\n",
    "        )\n",
    "\n",
    "        print(\"Finishing creating training data. Now returning....\")\n",
    "        return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make the output neurons return from the music_helper where the data processing\n",
    "# actually happens\n",
    "LOSS_FUNC = \"sparse_categorical_crossentropy\"\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 16\n",
    "NUM_NEURONS = [256] # number of neurons in the eternal layers\n",
    "ROOT_PATH = Path.cwd()\n",
    "SAVE_MODEL_PATH = f\"{ROOT_PATH}/Piano.h5\"\n",
    "\n",
    "# Used with the music helper class\n",
    "pipeline_config = {\n",
    "    'DATASET_PATH': f\"{ROOT_PATH}/data\",\n",
    "    'ENCODED_SONG_PATH': f\"{ROOT_PATH}/processed_songs/\",\n",
    "    'MAJOR_KEY': \"C\",\n",
    "    'MINOR_KEY': \"A\",\n",
    "    'SINGLE_FILE_DATASET_PATH': f\"{ROOT_PATH}/massive_song_file_data.txt\",\n",
    "    'MAPPING_PATH': f\"{ROOT_PATH}/song_mappings.json\",\n",
    "    'SEQUENCE_LENGTH': 64,\n",
    "    'FILE_TYPE': \"mid\",\n",
    "    'STAGE': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_helper = FileHelper()\n",
    "music_helper = MusicHelper(file_helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "inputs, targets = music_helper.song_data_pipeline(\n",
    "            pipeline_config\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(output_neurons, num_neurons, loss, learning_rate):\n",
    "\n",
    "    # Create the model architecture, functionally!\n",
    "    # If we say None for the shape, it lets us have any length input for the time steps\n",
    "    # This is important because we might wanna feed it different length premade sequences\n",
    "    input = keras.layers.Input(shape=(None, output_neurons))\n",
    "    x = keras.layers.LSTM(num_neurons[0]*2)(input) # This links the layers together\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    dense = keras.layers.Dense(num_neurons[0], activation=\"relu\")(x)\n",
    "    dense = keras.layers.Dropout(0.3)(dense)\n",
    "    dense = keras.layers.Dense(num_neurons[0]//2, activation=\"relu\")(dense)\n",
    "    dense = keras.layers.Dropout(0.3)(dense)\n",
    "    output = keras.layers.Dense(output_neurons, activation=\"softmax\")(dense)\n",
    "\n",
    "    # compile the model\n",
    "    model = keras.Model(input, output)\n",
    "    model.compile(loss=loss,\n",
    "                optimizer=keras.optimizers.Adam(lr=learning_rate),\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set any callbacks\n",
    "checkpoint_path = f\"{ROOT_PATH}/checkpoints/cp.ckpt\"\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_NEURONS = len(file_helper.loadJSON(\"./song_mappings.json\").keys())\n",
    "OUTPUT_NEURONS # Equal to vocabulary size from the mapping.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(OUTPUT_NEURONS, NUM_NEURONS, LOSS_FUNC, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_EPOCHS = 200\n",
    "model.fit(inputs, targets, epochs=TOTAL_EPOCHS, batch_size=BATCH_SIZE, callbacks=[cp_callback])\n",
    "\n",
    "# save the model\n",
    "model.save(SAVE_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
